{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Music genre classifier","metadata":{}},{"cell_type":"markdown","source":"The objective of this project is to classify 30 sec wav files by genre using a TensorFLow LSTM model. Dataset:https://www.kaggle.com/andradaolteanu/gtzan-dataset-music-genre-classification\n\nTo classify audio samples, we will preprocess them by calculating their MFCC, which is a temporal representation of the energy for each perceived frequency band. In this case, we are choosing 13 bands.","metadata":{}},{"cell_type":"code","source":"import os\nimport json\nimport numpy as np\nimport librosa\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\n\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2022-06-04T12:29:17.541229Z","iopub.execute_input":"2022-06-04T12:29:17.541502Z","iopub.status.idle":"2022-06-04T12:29:17.551319Z","shell.execute_reply.started":"2022-06-04T12:29:17.541474Z","shell.execute_reply":"2022-06-04T12:29:17.550326Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"SOURCE_PATH = '/kaggle/input/gtzan-dataset-music-genre-classification/Data/genres_original/'\n\n# Path to labels and processed data file, json format.\nJSON_PATH = '/kaggle/working/data.json'\n\n# Sampling rate.\nsr = 22050\n\n# Let's make sure all files have the same amount of samples and pick a duration right under 30 seconds.\nTOTAL_SAMPLES = 29 * sr\n\n# The dataset contains 999 files. Lets make it bigger. \n# X amount of slices => X times more training examples.\nNUM_SLICES = 10\nSAMPLES_PER_SLICE = int(TOTAL_SAMPLES / NUM_SLICES)","metadata":{"execution":{"iopub.status.busy":"2022-06-04T12:29:22.601673Z","iopub.execute_input":"2022-06-04T12:29:22.601919Z","iopub.status.idle":"2022-06-04T12:29:22.606364Z","shell.execute_reply.started":"2022-06-04T12:29:22.601892Z","shell.execute_reply":"2022-06-04T12:29:22.605471Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"def preprocess_data(source_path, json_path):\n\n    # Let's create a dictionary of labels and processed data.\n    mydict = {\n        \"labels\": [],\n        \"mfcc\": []\n        }\n\n    # Let's browse each file, slice it and generate the 13 band mfcc for each slice.\n    for i, (dirpath, dirnames, filenames) in enumerate(os.walk(source_path)):\n        for file in filenames:\n            # exclude a corrupted wav file that makes everything crash.\n            if os.path.join(dirpath, file) != '/kaggle/input/gtzan-dataset-music-genre-classification/Data/genres_original/jazz/jazz.00054.wav':\n                song, sr = librosa.load(os.path.join(dirpath, file), duration=29)\n                for s in range(NUM_SLICES):\n                    start_sample = SAMPLES_PER_SLICE * s\n                    end_sample = start_sample + SAMPLES_PER_SLICE\n                    mfcc = librosa.feature.mfcc(y=song[start_sample:end_sample], sr=sr, n_mfcc=13)\n                    mfcc = mfcc.T\n                    mydict[\"labels\"].append(i-1)\n                    mydict[\"mfcc\"].append(mfcc.tolist())\n            else:\n                pass\n\n    # Let's write the dictionary in a json file.    \n    with open(json_path, 'w') as f:\n        json.dump(mydict, f)\n    f.close()","metadata":{"execution":{"iopub.status.busy":"2022-06-04T12:29:26.917202Z","iopub.execute_input":"2022-06-04T12:29:26.917469Z","iopub.status.idle":"2022-06-04T12:29:26.926710Z","shell.execute_reply.started":"2022-06-04T12:29:26.917439Z","shell.execute_reply":"2022-06-04T12:29:26.925378Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"def load_data(json_path):\n\n    with open(json_path, 'r') as f:\n        data = json.load(f)\n    f.close()\n\n    # Let's load our data into numpy arrays for TensorFlow compatibility.\n    X = np.array(data[\"mfcc\"])\n    y = np.array(data[\"labels\"])\n\n    return X, y","metadata":{"execution":{"iopub.status.busy":"2022-06-04T12:29:29.943442Z","iopub.execute_input":"2022-06-04T12:29:29.944075Z","iopub.status.idle":"2022-06-04T12:29:29.951093Z","shell.execute_reply.started":"2022-06-04T12:29:29.944039Z","shell.execute_reply":"2022-06-04T12:29:29.950327Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"def prepare_datasets(inputs, targets, split_size):\n    \n    # Creating a validation set and a test set.\n    inputs_train, inputs_val, targets_train, targets_val = train_test_split(inputs, targets, test_size=split_size)\n    inputs_train, inputs_test, targets_train, targets_test = train_test_split(inputs_train, targets_train, test_size=split_size)\n    \n    # Our CNN model expects 3D input shape.\n    inputs_train = inputs_train[..., np.newaxis]\n    inputs_val = inputs_val[..., np.newaxis]\n    inputs_test = inputs_test[..., np.newaxis]\n    \n    return inputs_train, inputs_val, inputs_test, targets_train, targets_val, targets_test","metadata":{"execution":{"iopub.status.busy":"2022-06-04T12:29:32.684150Z","iopub.execute_input":"2022-06-04T12:29:32.684584Z","iopub.status.idle":"2022-06-04T12:29:32.690962Z","shell.execute_reply.started":"2022-06-04T12:29:32.684540Z","shell.execute_reply":"2022-06-04T12:29:32.690130Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"def design_model(input_shape):\n\n    # Let's design the model architecture.\n    model = tf.keras.models.Sequential([\n        \n        tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=input_shape),\n        tf.keras.layers.MaxPooling2D((3,3), strides=(2,2), padding='same'),\n        tf.keras.layers.BatchNormalization(),\n        \n        tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n        tf.keras.layers.MaxPooling2D((3,3), strides=(2,2), padding='same'),\n        tf.keras.layers.BatchNormalization(),\n        \n        tf.keras.layers.Conv2D(32, (2,2), activation='relu'),\n        tf.keras.layers.MaxPooling2D((3,3), strides=(2,2), padding='same'),\n        tf.keras.layers.BatchNormalization(),\n        tf.keras.layers.Dropout(0.3),\n        \n        tf.keras.layers.Flatten(),\n        tf.keras.layers.Dense(64, activation='relu'), \n        tf.keras.layers.Dense(len(np.unique(targets)), activation='softmax')\n    ])\n\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-06-04T12:29:35.667688Z","iopub.execute_input":"2022-06-04T12:29:35.668271Z","iopub.status.idle":"2022-06-04T12:29:35.678070Z","shell.execute_reply.started":"2022-06-04T12:29:35.668232Z","shell.execute_reply":"2022-06-04T12:29:35.677379Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"def make_prediction(model, X, y, idx):\n    \n    genre_dict = {\n        0 : \"blues\",\n        1 : \"classical\",\n        2 : \"country\",\n        3 : \"disco\",\n        4 : \"hiphop\",\n        5 : \"jazz\",\n        6 : \"metal\",\n        7 : \"pop\",\n        8 : \"reggae\",\n        9 : \"rock\",\n        }\n        \n    predictions = model.predict(X)\n    genre = np.argmax(predictions[idx])\n    \n    print(\"\\n---Now testing the model for one audio file---\\nThe model predicts: {}, and ground truth is: {}.\\n\".format(genre_dict[genre], genre_dict[y[idx]]))","metadata":{"execution":{"iopub.status.busy":"2022-06-04T12:29:38.386755Z","iopub.execute_input":"2022-06-04T12:29:38.387142Z","iopub.status.idle":"2022-06-04T12:29:38.398722Z","shell.execute_reply.started":"2022-06-04T12:29:38.387094Z","shell.execute_reply":"2022-06-04T12:29:38.397924Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"def plot_performance(hist):\n    \n    acc = hist.history['acc']\n    val_acc = hist.history['val_acc']\n    loss = hist.history['loss']\n    val_loss = hist.history['val_loss']\n\n    epochs = range(len(acc))\n\n    plt.plot(epochs, acc, 'r', label='Training accuracy')\n    plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n    plt.title('Training and validation accuracy')\n    plt.legend()\n    plt.figure()\n\n    plt.plot(epochs, loss, 'r', label='Training Loss')\n    plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n    plt.title('Training and validation loss')\n    plt.legend()\n\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-04T12:29:40.685354Z","iopub.execute_input":"2022-06-04T12:29:40.685624Z","iopub.status.idle":"2022-06-04T12:29:40.692314Z","shell.execute_reply.started":"2022-06-04T12:29:40.685595Z","shell.execute_reply":"2022-06-04T12:29:40.691640Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"if __name__ == \"__main__\":\n\n    preprocess_data(source_path=SOURCE_PATH, json_path=JSON_PATH)\n    \n    inputs, targets = load_data(json_path=JSON_PATH)\n    \n    Xtrain, Xval, Xtest, ytrain, yval, ytest = prepare_datasets(inputs, targets, 0.2)\n\n    input_shape = (Xtrain.shape[1], Xtrain.shape[2], 1)\n    model = design_model(input_shape)\n\n    # Selection of the optimizer, loss type and metrics for performance evaluation.\n    model.compile(optimizer = tf.keras.optimizers.RMSprop(lr=0.001),\n                     loss='sparse_categorical_crossentropy',\n                     metrics = ['acc']\n                     )\n\n    model.summary()\n\n    #Training the model.\n    history = model.fit(Xtrain, ytrain,\n                        validation_data=(Xval, yval),\n                        epochs=30,\n                        batch_size=32\n                        )\n\n    plot_performance(history)\n\n    # Testing the model on never seen before data.\n    make_prediction(model, Xtest, ytest, 24)","metadata":{"execution":{"iopub.status.busy":"2022-06-04T12:29:43.087194Z","iopub.execute_input":"2022-06-04T12:29:43.087464Z","iopub.status.idle":"2022-06-04T12:32:58.954134Z","shell.execute_reply.started":"2022-06-04T12:29:43.087430Z","shell.execute_reply":"2022-06-04T12:32:58.952911Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"**The End**","metadata":{}}]}